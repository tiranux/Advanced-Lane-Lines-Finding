{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#This method calibrates the camera based on a classic example of a chessboard. This is an easy and well proven way\n",
    "# to calibrate a camera.\n",
    "def calibrateCamera():\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Load an image to perform calibration\n",
    "    img = cv2.imread('../camera_cal/calibration2.jpg')\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "\n",
    "    # Add object points, image points\n",
    "    objpoints.append(objp)\n",
    "    imgpoints.append(corners)\n",
    "\n",
    "    # Draw and display the corners\n",
    "    ##img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "            \n",
    "    return ret, mtx, dist, rvecs, tvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function performs color thresolding using HLS color space. \n",
    "# Specifically, the thresholding is applied on H channel\n",
    "def threshold_hls(img, thresh=(0, 255)):\n",
    "    threshMin = thresh[0]\n",
    "    threshMax = thresh[1]\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    H = hls[:,:,2]\n",
    "    binary = np.zeros_like(H)\n",
    "    binary[(H > threshMin) & (H <= threshMax)] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    binary_output = binary \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function performs absolute sobel thresolding using HLS color space.\n",
    "# It performs threshold X gradient on L channel and threshold color channel on S channel.\n",
    "# The result of both is combined ant the one-channel picture is returned.\n",
    "def abs_sobel_thresh_hls(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    \n",
    "    # Applying Sobel on X direction\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    # Return combined binary\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that performs X or Y Sobel treshold on a color RGB picture\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))# Take the derivative in x\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))# Take the derivative in y\n",
    "    \n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Performs a blind search creating a histogram to detec peaks which would indicate lane lines detected\n",
    "def blindSearch(binary_warped, visualize = False):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 110\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 90\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    if visualize == True:\n",
    "        plt.imshow(out_img)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lineFinding(binary_warped, left_fit, right_fit, visualize=False):    \n",
    "    # from the next frame of video (called \"binary_warped\") we can detect the lane lines based on \n",
    "    # fitted values (left_fit, right_fit).\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Define a margin for the window where it searchs for lines detected\n",
    "    margin = 60\n",
    "    # Gets the indexes of pixels where lines were detected\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    if sum(leftx)< 500 or sum(rightx)<500:\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    #And you're done!. We can also visualize the result here as well\n",
    "\n",
    "    if visualize == True:\n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculateCurvature(left_fitx, right_fitx, ploty, plot=False):\n",
    "    leftx = left_fitx\n",
    "    rightx = right_fitx\n",
    "    # Fit a second order polynomial to pixel positions in each lane line\n",
    "    left_fit = np.polyfit(ploty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit = np.polyfit(ploty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "  \n",
    "    #Now we have polynomial fits and we can calculate the radius of curvature as follows:\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    #print(left_curverad, right_curverad)\n",
    "    # Example values: 1926.74 1908.48\n",
    "\n",
    "    #But now we need to stop and think... We've calculated the radius of curvature based on pixel values, so the radius we are reporting is in pixel space, which is not the same as real world space. So we actually need to repeat this calculation after converting our x and y values to real world space.\n",
    "    #This involves measuring how long and wide the section of lane is that we're projecting in our warped image. We could do this in detail by measuring out the physical lane in the field of view of the camera, but for this project, you can assume that if you're projecting a section of lane similar to the images above, the lane is about 30 meters long and 3.7 meters wide. Or, if you prefer to derive a conversion from pixel space to world space in your own images, compare your images with U.S. regulations that require a minimum lane width of 12 feet or 3.7 meters, and the dashed lane lines are 10 feet or 3 meters long each.\n",
    "    #So here's a way to repeat the calculation of radius of curvature after correcting for scale in x and y:\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/600 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/540 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    return left_curverad, right_curverad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotLines(warped, original, linesDetected):\n",
    "    \n",
    "    # Extract needed variables from Line instance\n",
    "    left_fitx, right_fitx = linesDetected.left_fitx, linesDetected.right_fitx\n",
    "    left_fit, right_fit = linesDetected.left_fit, linesDetected.right_fit\n",
    "    Minv, ploty = linesDetected.Minv, linesDetected.ploty\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Based on lines already detected, search for lane lines with a smaller margin, in order to eliminate the noise\n",
    "    # This is not really necesary, it is done just to draw the lane lines as limits \n",
    "    margin = 40\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))    \n",
    "    \n",
    "    # Based on lane detected, gets point for the lane lines\n",
    "    ptsL = np.hstack((np.array([np.transpose(np.vstack([left_fitx-15, ploty]))]),  np.array([np.flipud(np.transpose(np.vstack([left_fitx+15, ploty])))])) )\n",
    "    ptsR = np.hstack((np.array([np.transpose(np.vstack([right_fitx-15, ploty]))]),  np.array([np.flipud(np.transpose(np.vstack([right_fitx+15, ploty])))])) )\n",
    "    \n",
    "    #Plot color lane lines\n",
    "    color_warp[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    color_warp[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.fillPoly(color_warp, np.int_([ptsL]), (255,0, 0))\n",
    "    cv2.fillPoly(color_warp, np.int_([ptsR]), (0,0, 255))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (original.shape[1], original.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(original, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undistort_warp(img, mtx, dist):\n",
    "    \n",
    "    # Undistort using mtx and dist\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Apply different image filters in order to get the most posible clean picture of the lane lines.\n",
    "    # Different filters are used, each of them detecting some particular pixels that will be joined later\n",
    "    # in a single picture. For more detail of each filter, please refer to each called method.\n",
    "    \n",
    "    # Result of filter threshold_hls (binary threshold on H channel)\n",
    "    result_flt  = threshold_hls(img, thresh=(110, 255))\n",
    "    # Result of filter abs_sobel_thresh_hls (binary sobel threshold on L,S channel)\n",
    "    result_flt2 = abs_sobel_thresh_hls(img,s_thresh=(170, 255), sx_thresh=(30,200))\n",
    "    # Result of filter abs_sobel_thresh(binary sobel threshold on RGB channel, Y direction)\n",
    "    result_flt3 = abs_sobel_thresh(img, orient='y', thresh_min=100, thresh_max=150)\n",
    "    # Result of filter abs_sobel_thresh(binary sobel threshold on RGB channel, X direction)\n",
    "    result_flt4 = abs_sobel_thresh(img, orient='x', thresh_min=20, thresh_max=255)\n",
    "    \n",
    "    # Create a black picture where we will put the pixels detecte by previous filters\n",
    "    combined_binary = np.zeros_like(result_flt)\n",
    "    # Turning on pixels by combining contours detected by the filters\n",
    "    combined_binary[(result_flt == 1) | (result_flt2 == 1) | (result_flt3 == 1) | (result_flt4 == 1)] = 1\n",
    "\n",
    "    # Get picture's shape\n",
    "    imshape = combined_binary.shape\n",
    "    \n",
    "    #Define vertices for the region of interest\n",
    "    vertices = np.array([[(150,imshape[0]),(540, 440), (770, 440), (imshape[1]-90,imshape[0])]], dtype=np.int32)\n",
    "    #vertices = np.array([[(150,imshape[0]),(600, 440), (720, 440), (imshape[1]-150,imshape[0])]], dtype=np.int32)\n",
    "     \n",
    "    # Remove unneeded information from picture by choosing a region of interest that will only keep the road\n",
    "    combined_binary = region_of_interest(combined_binary, vertices)\n",
    "    \n",
    "    # Define 4 source points for perspective transformation\n",
    "    src = np.float32([[480, 510], [800, 510], [80,720], [1200,720]])\n",
    "    dst = np.float32([[330, 510], [985, 510], [300,720], [1000, 720]])\n",
    "    \n",
    "    #Compute the perspective transform:\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    #Compute the inverse perspective transform:\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    #Warp the image using the perspective transform, M:\n",
    "    warped = cv2.warpPerspective(combined_binary, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Class created to keep track of detected lines\n",
    "class Line():\n",
    "    \n",
    "    def __init__(self, left_fit, right_fit, left_fitx, right_fitx, ploty, Minv, imgShape ):\n",
    "        #Inverse perspective\n",
    "        self.Minv = Minv\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # lines detected in search\n",
    "        self.left_fit = left_fit\n",
    "        self.right_fit = right_fit\n",
    "        # lines created based on search detection\n",
    "        self.left_fitx = left_fitx\n",
    "        self.right_fitx = right_fitx\n",
    "        # Y values for lines\n",
    "        self.ploty = ploty\n",
    "        # radius of curvature per line\n",
    "        self.left_curverad = None\n",
    "        self.right_curverad = None\n",
    "        # Image shape\n",
    "        self.imgShape = imgShape\n",
    "        \n",
    "    # Calculate distance to the center of the road\n",
    "    def getLineBasePos(self):\n",
    "        xm_per_pix = 3.7/540 # meters per pixel in x dimension    \n",
    "        camera_center = (self.left_fitx[-1] + self.right_fitx[-1])/2 #Assumes camera is perfectly centered\n",
    "        center_diff = (camera_center - self.imgShape[1]/2)*xm_per_pix #Calculates based on lines detected\n",
    "        return center_diff\n",
    "    \n",
    "    # Checks if the lines are separated by at least 3.7 m.\n",
    "    def isGoodSeparation(self):\n",
    "        xm_per_pix = 3.7/540 # meters per pixel in x dimension    \n",
    "        lines_distance = ( np.max(self.right_fitx) - np.min(self.left_fitx))*xm_per_pix #Calculates based on lines detected\n",
    "        if lines_distance < 3.7:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    # Average the over the last 10 well detected iterations so that lines are smoother\n",
    "    def setLineAverage(self, colaL, colaR, reset):\n",
    "        colaL.append(self.left_fit)\n",
    "        colaR.append(self.right_fit)\n",
    "        # Averages only is there is more than one line already detected\n",
    "        if len(colaL)>1:\n",
    "            self.left_fit, self.right_fit = np.mean(colaL, axis=0), np.mean(colaR, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Checks if lines detected make sense in comparison to previous good lines\n",
    "def goodLines(prevLine, newDetected):\n",
    "    # Calculates the sum of squares of the difference of x fits\n",
    "    s = np.sum((prevLine.left_fitx-newDetected.left_fitx)**2)\n",
    "    s2 = np.sum((prevLine.left_fitx-newDetected.left_fitx)**2)\n",
    "    # maxium difference allowed\n",
    "    sqrtSumMax = 300000\n",
    "    # If any of the lines has a greater difference, it means that lines are not very similar to previous ones\n",
    "    if (s > sqrtSumMax):\n",
    "        return False\n",
    "    if (s2 > sqrtSumMax):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def processImagePipeline(img):\n",
    "    \n",
    "    # Start by getting an undistorted and warped binary picture where the lane lines are visible and ready to \n",
    "    # be detected. Also saves perspective transformation and it's inverse. \n",
    "    undistorted, perspective_M, Minv = undistort_warp(img, mtx, dist)\n",
    "    global firstRun, prevLines, newLines, colaL, colaR, isGoodDetection, wrongConsecutive,resetSearch\n",
    "    \n",
    "    # Check if it is first run \n",
    "    if firstRun == True or resetSearch == True:\n",
    "        # If first run, then uses blind search to detec the lines.\n",
    "        left_fit, right_fit, left_fitx, right_fitx, ploty = blindSearch(undistorted, visualize=False)\n",
    "        prevLines = Line(left_fit, right_fit, left_fitx, right_fitx, ploty, Minv, img.shape) \n",
    "        # Calculates radius of curvature for detected lines\n",
    "        left_curverad, right_curverad = calculateCurvature(prevLines.left_fitx, prevLines.right_fitx, prevLines.ploty, plot=False)\n",
    "        prevLines.left_curverad, prevLines.right_curverad = left_curverad, right_curverad\n",
    "        \n",
    "        if resetSearch == True:\n",
    "            colaL.clear()\n",
    "            colaR.clear()\n",
    "        \n",
    "        firstRun = False\n",
    "        resetSearch = False\n",
    "        wrongConsecutive = 0\n",
    "        \n",
    "    else:\n",
    "        # If not the first run, it can use the previous lines to detec the new ones.\n",
    "        left_fit, right_fit, left_fitx, right_fitx, ploty = lineFinding(undistorted, prevLines.left_fit, prevLines.right_fit, visualize=False) \n",
    "        if left_fit == None:\n",
    "            wrongConsecutive += 1\n",
    "            left_fit, right_fit, left_fitx, right_fitx, ploty = prevLines.left_fit, prevLines.right_fit, prevLines.left_fitx, prevLines.right_fitx, prevLines.ploty\n",
    "        \n",
    "        # Calculates radius of curvature for detected lines\n",
    "        left_curverad, right_curverad = calculateCurvature(left_fitx, right_fitx, ploty, plot=False)\n",
    "   \n",
    "    # if last detection was not good, remove the values from the queue\n",
    "    # so that they don't mess the average\n",
    "    if  isGoodDetection == False:\n",
    "        wrongConsecutive += 1\n",
    "        if len(colaR)>0:\n",
    "            colaR.pop()\n",
    "            colaL.pop()\n",
    "        else:\n",
    "            resetSearch=True\n",
    "    else:\n",
    "        wrongConsecutive = 0\n",
    "        \n",
    "    if wrongConsecutive == 3:\n",
    "        resetSearch = True\n",
    "    \n",
    "    \n",
    "    # Create an instance with new lines detected and add curve radius\n",
    "    newLines = Line(left_fit, right_fit, left_fitx, right_fitx, ploty, Minv, img.shape)\n",
    "    newLines.left_curverad, newLines.right_curverad = left_curverad, right_curverad \n",
    "    \n",
    "    # Are the lines correctly detected in comparison to previous lines?\n",
    "    isGoodDetection = goodLines(prevLines, newLines)\n",
    "    if newLines.isGoodSeparation() == False:\n",
    "            resetSearch = True\n",
    "            print(\"no good separation\")\n",
    "    \n",
    "    # Averages lines coordinates \n",
    "    newLines.setLineAverage(colaL, colaR, False)\n",
    "    \n",
    "    prevLines = newLines\n",
    "    \n",
    "    # Gets final picture whit lane plotted\n",
    "    finalPicture = plotLines(undistorted, img, newLines)\n",
    "    # Message if a frame had bad detection\n",
    "    error=''\n",
    "    if isGoodDetection == False:\n",
    "        error = 'Bad detection'\n",
    "        print(error)\n",
    "    \n",
    "    # Print in the frame the radius of curvature and distance to the center\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(finalPicture, error, (200, 20), font, 0.8, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(finalPicture, 'Radius of Curvature: '+ str(round(newLines.right_curverad, 3)) + ' m', (200, 50), font, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(finalPicture, 'Center Distance: '+ str(round(newLines.getLineBasePos(),2)) + ' m', (200, 75), font, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return finalPicture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Useful to indicate first run (meaning blind search and no prev lines)\n",
    "firstRun = True\n",
    "# Indicate reset search (blind search again)\n",
    "resetSearch = False\n",
    "# To check if lines detected are \"good\"\n",
    "isGoodDetection = True\n",
    "\n",
    "# Queues to store last 10 detectec lines\n",
    "colaR = deque(maxlen=10)\n",
    "colaL = deque(maxlen=10)\n",
    "\n",
    "# wrong in a row\n",
    "wrongConsecutive=0\n",
    "\n",
    "# Variables that will be used as instance of Line class\n",
    "prevLines, newLines = None, None\n",
    "\n",
    "# Output video with lane plotted\n",
    "white_output = '../videos/project_video_result.mp4'\n",
    "# Input video\n",
    "clip1 = VideoFileClip(\"../videos/project_video.mp4\")\n",
    "\n",
    "# Calibrate camera before start processing the frames.\n",
    "# we get the camera matrix, distortion coefficients, rotation and translation vectors etc.\n",
    "ret, mtx, dist, rvecs, tvecs = calibrateCamera()\n",
    "# Process the video frame by frame calling processImagePipeline\n",
    "white_clip = clip1.fl_image(processImagePipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CV_keras]",
   "language": "python",
   "name": "conda-env-CV_keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
